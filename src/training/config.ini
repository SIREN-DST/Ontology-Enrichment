[DEFAULT]

# The domain of the ontology: Just for a naming convention
domain = security

# Folder for storing all output files, including trained model and predicted results
output_folder = ../../files/output/

[dataset]

# Training dataset
train_file = ../../files/datasets/security/train.tsv

# Testing dataset (DBPedia)
test_file = ../../files/datasets/security/test.tsv

# Testing dataset (Knocked-out concepts)
test_knocked = ../../files/datasets/security/test_knocked.tsv

[preprocessing]

# File containing dict resolving words missing from the db to its closest match, computed through USE similarity.
resolved_file = ../../files/preprocessing/security/resolved.pkl

# Preprocessed db file containing word to id mappings
word2id_db = ../../files/preprocessing/security/w2i.pkl

# Preprocessed db file containing id to word mappings
id2word_db = ../../files/preprocessing/security/i2w.pkl

# Preprocessed db file containing path to id mappings
path2id_db = ../../files/preprocessing/security/p2i.pkl

# Preprocessed db file containing id to path mappings
id2path_db = ../../files/preprocessing/security/i2p.pkl

# Preprocessed db file storing paths given term pairs
relations_db = ../../files/preprocessing/security/relations.pkl


[parameters]

# Resolve to closest word in corpus if semantic similarity is greater than this threshold
resolve_threshold = 0.86

# Embedding layer dropout
emb_dropout = 0.35

# Hidden layer dropout
hidden_dropout = 0.8

# Number of layers
NUM_LAYERS = 2

# LSTM hidden dimension
HIDDEN_DIM = 180

# Layer 1 output dimension
LAYER1_DIM = 120

# Learning rate
lr = 0.001

# Number of epochs
epochs = 200

# Weight Decay
weight_decay = 0.001

# Batch size
batch_size = 32